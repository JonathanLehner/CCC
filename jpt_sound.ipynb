{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracts features from audio files and converts into numpy\n",
    "import librosa\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "\n",
    "##save the current directory\n",
    "cwd = os.getcwd()\n",
    "\n",
    "##change to sound file directory\n",
    "audio_dir = '/Users/panchanok/Desktop/PyHack2019/sound/tone_perfect/'\n",
    "os.chdir(audio_dir)\n",
    "\n",
    "##list files in the directory\n",
    "audio_files = os.listdir(audio_dir)[0:10]\n",
    "#print(audio_files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "global hop_length\n",
    "\n",
    "# Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "hop_length = 128\n",
    "\n",
    "## return a one-D array with mcff, mcff_delta, and chomagram of the audio file\n",
    "def getMFCC(audio_file):\n",
    "    \n",
    "    print('*getting ', audio_file)\n",
    "    y, sr = librosa.load(audio_file)\n",
    "    # Compute MFCC features from the raw signal\n",
    "    return librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13).flatten()\n",
    "\n",
    "\n",
    "def getChroma(audio_file):\n",
    "    \n",
    "    y, sr = librosa.load(audio_file)\n",
    "    # Separate harmonics and percussives into two waveforms\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    \n",
    "    # Compute chroma features from the harmonic signal\n",
    "    return librosa.feature.chroma_cqt(y=y_harmonic,\n",
    "                                            sr=sr).flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return a 2-d array of MFCC padded with 0's\n",
    "## Each array element is of an audio\n",
    "def getPaddedMFCC(audio_files):\n",
    "    input = [getMFCC(f) for f in audio_files]\n",
    "    \n",
    "    ##pad arrays with 0's. Get arrays of size Max\n",
    "    max_len = max([len(x) for x in input])\n",
    "    padded = [np.pad(x, (0, max_len - len(x))) for x in input]\n",
    "    \n",
    "    ##sanity check\n",
    "    is_shorter = sum([len(x) - max_len for x in padded])\n",
    "    if is_shorter < 0:\n",
    "        print('not padded well')\n",
    "        return -1\n",
    "    else:\n",
    "        return padded\n",
    "    \n",
    "## return a 2-d array of chromagram   ,y h .    padded with 0's\n",
    "## Each array element is of an audio\n",
    "def getPaddedChroma(audio_files):\n",
    "    input = [getChroma(f) for f in audio_files]\n",
    "    \n",
    "    ##pad arrays with 0's. Get arrays of size Max\n",
    "    max_len = max([len(x) for x in input])\n",
    "    padded = [np.pad(x, (0, max_len - len(x))) for x in input]\n",
    "    \n",
    "    ##sanity check\n",
    "    is_shorter = sum([len(x) - max_len for x in padded])\n",
    "    if is_shorter < 0:\n",
    "        print('not padded well')\n",
    "        return -1\n",
    "    else:\n",
    "        return padded "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*getting  sa3_MV1_MP3.mp3\n",
      "*getting  cao2_FV1_MP3.mp3\n",
      "*getting  hong1_MV2_MP3.mp3\n",
      "*getting  zheng3_MV3_MP3.mp3\n",
      "*getting  shao4_MV1_MP3.mp3\n",
      "*getting  ke4_MV3_MP3.mp3\n",
      "*getting  kai4_MV2_MP3.mp3\n",
      "*getting  ken4_FV3_MP3.mp3\n",
      "*getting  chu3_FV1_MP3.mp3\n",
      "*getting  nong4_FV1_MP3.mp3\n"
     ]
    }
   ],
   "source": [
    "mfcc = getPaddedMFCC(audio_files)\n",
    "chrom = getPaddedChroma(audio_files)\n",
    "\n",
    "## concatenate mfcc and chrom features\n",
    "att_input = [np.hstack([m, c]) for m, c in zip(mfcc, chrom)]\n",
    "\n",
    "## checking the final length\n",
    "#print(len(mfcc[5]), len(chrom[5]), len(x[5]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "##detect targets from sound names\n",
    "p = re.compile('^[aeo]|[bcdfghjklmnpqrstwz]+(?=[aeou])')\n",
    "#sample = 'wei'\n",
    "\n",
    "#p.match(sample).group()\n",
    "target = [p.match(f).group() for f in audio_files]\n",
    "\n",
    "## check corrrectness\n",
    "#print(target)\n",
    "#print(audio_files)\n",
    "\n",
    "\n",
    "## tag labels to attributes\n",
    "labeled_input = [np.hstack([i, l]) for i, l in zip(att_input, target)]\n",
    "\n",
    "## check final lengths\n",
    "#print(len(att_input[3]), len(labeled_input[3]), labeled_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2676"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_input[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
