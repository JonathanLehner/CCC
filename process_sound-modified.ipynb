{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracts features from audio files and converts into numpy\n",
    "import librosa, pickle\n",
    "import numpy as np\n",
    "import os, re, csv, sys\n",
    "from datetime import datetime\n",
    "from random import shuffle\n",
    "\n",
    "global hop_length, mfcc_len\n",
    "# global att, tar\n",
    "# Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "hop_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return a (flatten) one-D array of mfcc of an audio file\n",
    "def getFlattenMFCC(audio_file):\n",
    "    try:\n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except FileNotFoundError:\n",
    "        print('No such file or directory')\n",
    "\n",
    "    # Compute MFCC features from the raw signal\n",
    "    print(audio_file)\n",
    "    return librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13).flatten()\n",
    "\n",
    "# def getFlattenChroma(audio_file):\n",
    "#     #print ('audio_file in getFlattenChroma: ', audio_file)\n",
    "    \n",
    "#     try: \n",
    "#         y, sr = librosa.load(audio_file)\n",
    "#     except FileNotFoundError:\n",
    "#         print('No such file or directory')\n",
    "#     #print('print audio_file inside getFlattenChroma: ', audio_file)\n",
    "#     y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "#     x = librosa.feature.chroma_cqt(y=y_harmonic,sr=sr)\n",
    "#     print('shape: ', x.shape)\n",
    "#     #return librosa.feature.chroma_cqt(y=y_harmonic,sr=sr).flatten()\n",
    "#     return x.flatten()\n",
    "\n",
    "def getChroma(audio_file):\n",
    "    #print ('audio_file in getFlattenChroma: ', audio_file)\n",
    "    \n",
    "    try: \n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except FileNotFoundError:\n",
    "        print('No such file or directory')\n",
    "    #print('print audio_file inside getFlattenChroma: ', audio_file)\n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    return librosa.feature.chroma_cqt(y=y_harmonic,sr=sr)\n",
    "\n",
    "\n",
    "## return a list of 1-d array of chromagram padded with 0's of ALL audio files\n",
    "def getPaddedChroma(chroma):\n",
    "\n",
    "    ##pad arrays with 0's. Get arrays of size Max\n",
    "    max_col = max([x.shape[1] for x in chroma])\n",
    "    padded = [np.pad(x, [(0,0), (0, max_col - x.shape[1])], mode = 'constant') for x in chroma]\n",
    "\n",
    "    ##sanity check\n",
    "    is_shorter = sum([x.shape[1] - max_col for x in padded])\n",
    "    if is_shorter < 0:\n",
    "        print('not padded well')\n",
    "        return -1\n",
    "    else:\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## return a list of 1-d array of MFCC padded with 0's of ALL audio files\n",
    "def getPaddedMFCC(audio_files, train = True):\n",
    "    \n",
    "    result = [getFlattenMFCC(f) for f in audio_files]\n",
    "\n",
    "    if train:\n",
    "        ##pad arrays with 0's. Get arrays of size Max\n",
    "        max_len = max([len(x) for x in result])\n",
    "    else:\n",
    "        max_len = mfcc_len\n",
    "        \n",
    "    padded = [np.pad(x, (0, max_len - len(x)), mode = 'constant') for x in result]\n",
    "\n",
    "    ##sanity check\n",
    "    is_shorter = sum([len(x) - max_len for x in padded])\n",
    "    if is_shorter < 0:\n",
    "        print('not padded well')\n",
    "        return -1\n",
    "    else:\n",
    "        return padded, max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_train_audio(file_list):\n",
    "    \n",
    "    print('Processing ', len(file_list), ' files')\n",
    "\n",
    "    ####MFCC\n",
    "#     mfcc = [getFlattenMFCC(f) for f in file_list]\n",
    "#     padded_mdcc, mfcc_len = getPaddedMFCC(mfcc)\n",
    "    \n",
    "    chroma = [getChroma(f) for f in file_list]\n",
    "    padded_chroma = getPaddedChroma(chroma)\n",
    "    #print (\"padded_chroma: \", padded_chroma[0])\n",
    "    \n",
    "    \n",
    "    \n",
    "    ### user cannot fix this\n",
    "#     assert (mfcc != -1 and chrom != -1), \"Audio process does not produce uniform format.\"\n",
    "\n",
    "    \n",
    "    \n",
    "    ## concatenate mfcc and chrom features\n",
    "#     attr_input = [np.hstack([m, c]) for m, c in zip(padded_mdcc, padded_chrom)]\n",
    "    attr_input = padded_chroma\n",
    "    ## checking the final length\n",
    "    #print(len(mfcc[5]), len(chrom[5]), len(x[5]))\n",
    "    \n",
    "    \n",
    "    ##detect targets from sound names\n",
    "    p = re.compile('^[aeou]|[bcdfghjklmnpqrstwxyz]+(?=[aeiou])')\n",
    "    splt_file = [f.split('/')[-1] for f in file_list]\n",
    "    \n",
    "    target_input = [p.match(f).group() for f in splt_file]\n",
    "    \n",
    "    print('Processing finished')\n",
    "    return attr_input, target_input\n",
    "\n",
    "##to process audio file for both validation and testing\n",
    "def process_validate_audio(file_list):\n",
    "    \n",
    "    print('Processing ', len(file_list), ' files')\n",
    "    \n",
    "    ####MFCC\n",
    "    mfcc = [getFlattenMFCC(f) for f in file_list]\n",
    "    padded_mdcc = getPaddedMFCC(mfcc)\n",
    "    chroma = [getFlattenChroma(f) for f in file_list]\n",
    "    padded_chroma = getPaddedChroma(chroma)\n",
    "    \n",
    "    ### user cannot fix this\n",
    "    assert (mfcc != -1 and chroma != -1), \"Audio process does not produce uniform format.\"\n",
    "\n",
    "    \n",
    "    \n",
    "    ## concatenate mfcc and chrom features\n",
    "    attr_input = [np.hstack([m, c]) for m, c in zip(padded_mdcc, padded_chroma)]\n",
    "    ## checking the final length\n",
    "    #print(len(mfcc[5]), len(chrom[5]), len(x[5]))\n",
    "\n",
    "\n",
    "    ##detect targets from sound names\n",
    "    p = re.compile('^[aeou]|[bcdfghjklmnpqrstwxyz]+(?=[aeiou])')\n",
    "    target_input = [p.match(f).group() for f in audio_files]\n",
    "    \n",
    "    print('Processing finished')\n",
    "    return attr_input, target_input     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  2352  files\n",
      "Processing finished\n"
     ]
    }
   ],
   "source": [
    "#audio_dir = '/Users/athicha/Desktop/PyHack2019/sound_samples/train/'\n",
    "audio_dir = '/Users/panchanok/Desktop/PyHack2019/PyHack2019/sound_samples/mix_samples/'\n",
    "all_files = [audio_dir + d for d in os.listdir(audio_dir)]\n",
    "shuffle(all_files)\n",
    "\n",
    "att, tar = process_train_audio(all_files)\n",
    "att_file = open(r'mix_chroma_attr.pkl', 'wb')\n",
    "pickle.dump(att, att_file)\n",
    "att_file.close()\n",
    "\n",
    "\n",
    "tar_file = open(r'mix_chroma_tar.pkl', 'wb')\n",
    "pickle.dump(tar, tar_file)\n",
    "tar_file.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If there is error from the above chunk, make sure only mp3 is included in aggr/. Check even invisible .ds_store"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
