{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwhyZMUV77py"
   },
   "source": [
    "Create a model using built-in library from Pytorch.\n",
    "This code closely follows nn_tutorial notebook.\n",
    "\n",
    "Multiple hyperhapameter combinations are tried to search for a best model. Mount the book to the Google drive if want to use Google GPU cloud."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 283
    },
    "colab_type": "code",
    "id": "lpNowfMn8Yjg",
    "outputId": "0787b879-31e6-4c0b-c7de-8a9e23d0c60b"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!pwd\n",
    "os.chdir('gdrive/My Drive/PyHack2019/')\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bcva0X3Q77pz",
    "outputId": "bdca266d-7991-4cbd-9596-203678870cc2"
   },
   "outputs": [],
   "source": [
    "import csv, torch, math, os, pickle\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "global chroma_shape, epochs, train_bs, validate_bs, lr, n_class\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "  \n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "XenlRrj677p2"
   },
   "outputs": [],
   "source": [
    "## read attr and tar in .pkl files\n",
    "## Param: ratio = training size to the sample size. \n",
    "##         E.g. 0.7 means using 70% of the samples as training \n",
    "##              sample and the rest as validation sample. \n",
    "## Return: (1) a list of padded attr arrays\n",
    "##         (2) a list of paddrd tar arrays\n",
    "def read_data(ratio):\n",
    "    \n",
    "    assert (ratio > 0 and ratio < 1), 'Invalid ratio'\n",
    "    \n",
    "    \n",
    "    att_file = open(r'data/eight_mfcc_noise_attr.pkl', 'rb')\n",
    "    x_train = pickle.load(att_file)  \n",
    "    att_file.close()\n",
    "    \n",
    "    tar_file = open(r'data/eight_mfcc_noise_tar.pkl', 'rb')\n",
    "    str_y_train = pickle.load(tar_file)\n",
    "    tar_file.close()\n",
    "    \n",
    "    y = []\n",
    "    class_map = ['c', 'ch', 'q', 's', 'sh', 'x', 'z', 'zh']\n",
    "    for s in str_y_train:\n",
    "        if s in class_map:\n",
    "            y.append(class_map.index(s))\n",
    "\n",
    "\n",
    "    y = torch.tensor(y)\n",
    "    \n",
    "    assert (len(x_train) == len(y)), 'Unequal sample lengths'\n",
    "    \n",
    "    x = torch.tensor(x_train).float() \n",
    "    divider = int(len(y)*ratio)\n",
    "       \n",
    "    x_train = x[:divider, :, :]\n",
    "    y_train = y[:divider]\n",
    "\n",
    "\n",
    "    x_validate = x[divider:, :, :]\n",
    "    y_validate = y[divider:]\n",
    "\n",
    "    assert (x_train.shape[0] + x_validate.shape[0] == len(y_train) + len(y_validate)), 'Lengths do not add up'\n",
    "\n",
    "    return x_train, y_train, x_validate, y_validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "7kaBqkp777p4",
    "outputId": "54d906e7-a8fb-4407-fe04-c128904d198c"
   },
   "outputs": [],
   "source": [
    "## create the train and the validation sets from processed file.\n",
    "x_train, y_train, x_validate, y_validate = read_data(0.7)\n",
    "\n",
    "x_train = x_train.to(device)\n",
    "y_train = y_train.to(device)\n",
    "x_validate = x_validate.to(device)\n",
    "y_validate = y_validate.to(device)\n",
    "\n",
    "print (x_train.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu6X0hrN77qC"
   },
   "outputs": [],
   "source": [
    "## the number of classes\n",
    "n_class = 8\n",
    "\n",
    "## Get the shape of a padded instance for model construction\n",
    "chroma_shape = x_train[0].shape\n",
    "\n",
    "n_train = x_train.shape[0]\n",
    "n_validate = x_validate.shape[0]\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLESp11v77qA"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    ##get the index with the max\n",
    "    preds = torch.argmax(out, dim = 1)\n",
    "    return (preds == yb).float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEQljRet77qF"
   },
   "source": [
    "Since there are three classes, we set D_out to 3. n is total number of instances and c is the number of attributes in each instance. We use a loss function from torch.nn.functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVCyO4dG77qG"
   },
   "outputs": [],
   "source": [
    "## Create a network class\n",
    "## Create one class and share with model_CNN_classify?\n",
    "class SoundRecognition_CNN(nn.Module):\n",
    "  \n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout_rate)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(16*3*116, n_class)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        \n",
    "        xb = xb.view(-1, 1, chroma_shape[0], chroma_shape[1])\n",
    "\n",
    "        xb = self.dropout(F.relu(self.conv1(xb)))\n",
    "        xb = self.dropout(F.relu(self.conv2(xb)))\n",
    "        xb = self.dropout(F.relu(self.conv3(xb)))\n",
    "\n",
    "        xb = self.pool(xb)\n",
    "\n",
    "        xb = xb.view(-1, 16*3*116)\n",
    "\n",
    "        xb = self.fc1(xb)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "## Get the model and optim object that will be used to update model parameters\n",
    "def get_model(dropout_rate, weight_decay, lr):\n",
    "    model = SoundRecognition_CNN(dropout_rate)\n",
    "    return model, optim.Adam(model.parameters(), weight_decay = weight_decay, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1G1YcC177qJ"
   },
   "outputs": [],
   "source": [
    "## PARAM: trained_model = trained model\n",
    "##        validate_bs = a batch of validation data\n",
    "##        n_validate = \n",
    "def validate(trained_model, validate_bs, n_validate):\n",
    "    trained_model.eval()\n",
    "    loss = []\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range((n_validate - 1) // validate_bs + 1):\n",
    "            start_i = i * validate_bs\n",
    "            end_i = start_i + validate_bs\n",
    "            #print(xb.shape)\n",
    "            xb = x_validate[start_i:end_i, :, :]\n",
    "            yb = y_validate[start_i:end_i]\n",
    "            pred = trained_model(xb)\n",
    "            loss.append(loss_func(pred, yb))\n",
    "            acc.append(accuracy(pred, yb))\n",
    "\n",
    "        #print(loss)\n",
    "        valid_loss = sum(loss)\n",
    "    return valid_loss, sum(acc)/len(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5gikDoBk77qO"
   },
   "outputs": [],
   "source": [
    "def fit(epochs = 100, \n",
    "        train_bs = 10, \n",
    "        n_train = n_train, \n",
    "        validate_bs = 20, \n",
    "        n_validate = n_validate,\n",
    "        dropout_rate = 0.5, \n",
    "        weight_decay = 1e-6, \n",
    "        lr = 1e-4,\n",
    "        tolerance = 0.05):\n",
    "  \n",
    "  \n",
    "    model, opt = get_model(dropout_rate = dropout_rate, weight_decay = weight_decay, lr = lr)\n",
    "    model.to(device)\n",
    "\n",
    "    ## to save training progress\n",
    "    text_file = ''\n",
    "    prev_small_vl = 10000000\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        #print('Training')\n",
    "        model.train()\n",
    "        for i in range((n_train - 1) // train_bs + 1):\n",
    "\n",
    "            start_i = i * train_bs\n",
    "            end_i = start_i + train_bs\n",
    "            xb = x_train[start_i:end_i, :, :]\n",
    "            yb = y_train[start_i:end_i]\n",
    "            pred = model(xb)\n",
    "            #print('pred: ', pred, ' | yb: ', yb)\n",
    "            loss = loss_func(pred, yb)\n",
    "\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "\n",
    "        valid_loss, acc = validate(model, validate_bs, n_validate)\n",
    "\n",
    "        ##early stop\n",
    "        if valid_loss < prev_small_vl:\n",
    "            prev_small_vl = valid_loss\n",
    "        elif valid_loss > prev_small_vl*(1+tolerance):\n",
    "            print('Epoch: ', epoch, ' == Early stop due to an increase in validation loss')\n",
    "            break\n",
    "\n",
    "    ## periodically report progress\n",
    "    if (epoch + 1)% 10 == 0:\n",
    "        print('Epoch: ', epoch + 1, ' | Loss: ', valid_loss, ' | Accuracy: ', acc)\n",
    "        text_file = text_file + 'Epoch: '+ str(epoch + 1) + ' | Loss: ' + str(valid_loss) + ' | Accuracy: ' + str(acc) + '\\n'\n",
    "    text_file = str(model) + '\\n\\n' + text_file\n",
    "    print('Train Finished')\n",
    "    return model, text_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GPr5gQfvDP2h"
   },
   "outputs": [],
   "source": [
    "##generate informative name for hyperparameter combinations\n",
    "def getName(epochs, dropout_rate, weight_decay, lr):\n",
    "    name = 'mfcc_m_' + str(epochs) + '_dr' + str(dropout_rate) + '_wc' + str(weight_decay) + '_lr' + str(try_lr)\n",
    "    return name +'.pt', name +'.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "39qDgFC177qV",
    "outputId": "931cafdb-2d95-47d6-e4f4-02b497420a44"
   },
   "outputs": [],
   "source": [
    "###### Make change under this this line########\n",
    "\n",
    "###############################################\n",
    "\n",
    "\n",
    "### run model with several sets of hyperparameters\n",
    "### the models and training results are saved\n",
    "\n",
    "## specify the directory to save the models\n",
    "model_dir = 'model8/'\n",
    "result_dir = 'result8/'\n",
    "\n",
    "wc_list = [1e-6]\n",
    "dr_list = [0.5, 0.8]\n",
    "lr_list = [1e-4, 1e-5, 1e-6]                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 \n",
    "\n",
    "# wc_list = [1e-5]  #[1e-3, 1e-4, 1e-5]\n",
    "# dr_list = [0, 0.1, 0.5, 0.75, 0.9] #[0, 0.1, 0.5, 0.75, 0.9]\n",
    "# lr_list = [1e-4, 1e-5, 1e-6]   #no wc -4 w/ dr .75 and dr .9 at all lr\n",
    "epochs = 10\n",
    "#dropout_rate = 0.5\n",
    "#weight_decay = 1e-6\n",
    "\n",
    "for try_wc in wc_list:\n",
    "    for try_dr in dr_list:\n",
    "        for try_lr in lr_list:\n",
    "            m_save_path, f_save_path = getName(epochs, try_dr, try_wc, try_lr)\n",
    "            print('Training: ', m_save_path)\n",
    "            m, t_file = fit(epochs = epochs, \n",
    "                      train_bs = 100, \n",
    "                      n_train = n_train, \n",
    "                      validate_bs = 200, \n",
    "                      n_validate = n_validate,\n",
    "                      dropout_rate = try_dr, \n",
    "                      weight_decay = try_wc, \n",
    "                      lr = try_lr,\n",
    "                      tolerance = 0.1)\n",
    "            print('DONE')\n",
    "\n",
    "#             torch.save(m, model_dir + m_save_path)\n",
    "#             file = open(result_dir + f_save_path,\"w\") \n",
    "#             file.write(t_file)\n",
    "#             file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "MFCC- model-CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
