{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "iwhyZMUV77py"
   },
   "source": [
    "Create a model using built-in library from Pytorch.\n",
    "This code closely follows nn_tutorial notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 104
    },
    "colab_type": "code",
    "id": "lpNowfMn8Yjg",
    "outputId": "cca74b74-7b8e-4579-e227-ef04c3e065d1"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')\n",
    "!pwd\n",
    "os.chdir('gdrive/My Drive/PyHack2019/')\n",
    "!pwd\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "Bcva0X3Q77pz",
    "outputId": "92a44451-5114-44f3-b382-039baf03477e"
   },
   "outputs": [],
   "source": [
    "import csv, math, os, pickle, torch\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "global chroma_shape, epochs, train_bs, validate_bs, lr, n_class\n",
    "\n",
    "# if torch.cuda.is_available():\n",
    "#   device = 'cuda'\n",
    "# else:\n",
    "#   device = 'cpu'\n",
    "  \n",
    "# print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rLESp11v77qA"
   },
   "outputs": [],
   "source": [
    "def accuracy(out, yb):\n",
    "    ##get the index with the max\n",
    "    preds = torch.argmax(out, dim = 1)\n",
    "    return (preds == yb).float().mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load record voice that is saved at temp_record.pkl\n",
    "\n",
    "att_file = open(r'mix_mfcc_attr.pkl', 'rb')\n",
    "x_validate = pickle.load(att_file)  \n",
    "att_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wu6X0hrN77qC"
   },
   "outputs": [],
   "source": [
    "if len(x_validate) == 1:\n",
    "    chroma_shape = x_validate.shape\n",
    "else:\n",
    "    chroma_shape = x_validate[0].shape\n",
    "\n",
    "\n",
    "#epochs = 50\n",
    "#train_bs = 20\n",
    "#validate_bs = train_bs*2\n",
    "#n_train = chroma_shape[0]\n",
    "n_validate = chroma_shape[0]\n",
    "n_class = 3\n",
    "loss_func = F.cross_entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fEQljRet77qF"
   },
   "source": [
    "Since there are three classes, we set D_out to 3. n is total number of instances and c is the number of attributes in each instance. We use a loss function from torch.nn.functional."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BVCyO4dG77qG"
   },
   "outputs": [],
   "source": [
    "class SoundRecognition_CNN(nn.Module):\n",
    "  \n",
    "    def __init__(self, dropout_rate):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n",
    "        self.conv3 = nn.Conv2d(16, 16, kernel_size=3, stride=1, padding=0)\n",
    "        \n",
    "        self.dropout = nn.Dropout(p = dropout_rate)\n",
    "        \n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "        self.fc1 = torch.nn.Linear(16*3, n_class)\n",
    "\n",
    "    def forward(self, xb):\n",
    "        #print(type(xb), len(xb))\n",
    "        \n",
    "        ## input of size (bs, 1, 13, 60)\n",
    "        print(xb.shape)\n",
    "        xb = xb.view(-1, 1, chroma_shape[0], chroma_shape[1])\n",
    "        #print('xb shape', xb.shape)\n",
    "        \n",
    "        ## (bs, 1, 13, 60) >> (bs, 16, 11, 58)\n",
    "        xb = self.dropout(F.relu(self.conv1(xb)))\n",
    "        #print('---xb shape2', xb.shape)\n",
    "        \n",
    "        ## (bs, 16, 11, 58) >> (bs, 16, 9, 56)\n",
    "        xb = self.dropout(F.relu(self.conv2(xb)))\n",
    "        #print('---xb shape3', xb.shape)\n",
    "        \n",
    "        ## (bs, 16, 9, 56) >> (bs, 16, 7, 54)\n",
    "        xb = self.dropout(F.relu(self.conv3(xb)))\n",
    "        #print('---xb shape4', xb.shape)\n",
    "        \n",
    "        ## (bs, 16, 7, 54) >> (bs, 16, 3, 27)\n",
    "        xb = self.pool(xb)\n",
    "        print('---xb shape5', xb.shape)\n",
    "        \n",
    "        ## reshape for fully connected\n",
    "        xb = xb.view(-1, 16*3*116)\n",
    "        print(xb.shape)\n",
    "        ## (bs, 16*3*27) >> (bs, 3)\n",
    "        xb = self.fc1(xb)\n",
    "        #print('---xb shape6', xb.shape)\n",
    "        #print('=====', xb.shape)\n",
    "        return xb.view(-1, xb.size(1))\n",
    "\n",
    "## Get the model and optim object that will be used to update model parameters\n",
    "def get_model(dropout_rate, weight_decay, lr):\n",
    "    model = SoundRecognition_CNN(dropout_rate)\n",
    "    return model, optim.Adam(model.parameters(), weight_decay = weight_decay, lr = lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "a1G1YcC177qJ"
   },
   "outputs": [],
   "source": [
    "def validate(trained_model, validate_bs, n_validate):\n",
    "    trained_model.eval()\n",
    "    loss = []\n",
    "    acc = []\n",
    "    with torch.no_grad():\n",
    "\n",
    "        for i in range((n_validate - 1) // validate_bs + 1):\n",
    "            start_i = i * validate_bs\n",
    "            end_i = start_i + validate_bs\n",
    "            #print(xb.shape)\n",
    "            xb = x_validate[start_i:end_i, :, :]\n",
    "            yb = y_validate[start_i:end_i]\n",
    "            pred = trained_model(xb)\n",
    "            loss.append(loss_func(pred, yb))\n",
    "            acc.append(accuracy(pred, yb))\n",
    "\n",
    "        #print(loss)\n",
    "        valid_loss = sum(loss)\n",
    "    return valid_loss, sum(acc)/len(acc)\n",
    "\n",
    "def classify_raw_out(pred):\n",
    "    \n",
    "    p = torch.argmax(pred, dim = 1)\n",
    "    return ['s' if c == 0 else 'x' if c == 1 else 'neither' for c in p]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "veLr5NFa77qa"
   },
   "outputs": [],
   "source": [
    "# Model class must be defined somewhere\n",
    "model = torch.load('mfcc_m_1000_dr0.5_wc0.001_lr1e-05.pt', map_location=torch.device('cpu'))\n",
    "y = model(torch.tensor(x_validate))\n",
    "classify_raw_out(y)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "model-CNN.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
