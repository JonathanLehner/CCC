{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extracts features from audio files and converts into numpy\n",
    "import librosa, pickle, random, librosa.display\n",
    "from random import shuffle\n",
    "import numpy as np\n",
    "import os, re, csv, sys\n",
    "#from random import shuffle\n",
    "import torch\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "global hop_length #, mfcc_len\n",
    "# global att, tar\n",
    "# Set the hop length; at 22050 Hz, 512 samples ~= 23ms\n",
    "hop_length = 128\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "## from Kagle tutorial. See https://www.kaggle.com/CVxTz/audio-data-augmentation\n",
    "def addWhiteNoise(audio):\n",
    "    noise = np.random.randn(len(audio))\n",
    "    return audio + 0.05*noise   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## param: audio_file = the name of an audio file to be extract\n",
    "## return: a 2D array of 13 MFCCs over time\n",
    "def getMFCC(audio_file):\n",
    "    \n",
    "    try: \n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except FileNotFoundError:\n",
    "        print('No such file or directory')\n",
    "    return librosa.feature.mfcc(y=y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "\n",
    "\n",
    "\n",
    "## param: audio_file = the name of an audio file to be extract\n",
    "## return: a 2D array of 12 pitches as chromagram over time\n",
    "def getChroma(audio_file):  \n",
    "    try: \n",
    "        y, sr = librosa.load(audio_file)\n",
    "    except FileNotFoundError:\n",
    "        print('No such file or directory')\n",
    "        \n",
    "    y_harmonic, y_percussive = librosa.effects.hpss(y)\n",
    "    return librosa.feature.chroma_cqt(y=y_harmonic,sr=sr)\n",
    "    \n",
    "    \n",
    "## return a list of 1-d array of MFCC padded with 0's at the end of ALL audio files\n",
    "## param: chroma = a list of 2D arrays. The 2D array is an output from getMFCC()\n",
    "## return: a list of 2D arrays whose columns are padded at the end with 0's\n",
    "##       so that they all have the same number of columns. \n",
    "def getPaddedMFCC(mfcc):\n",
    "\n",
    "    print(mfcc)\n",
    "    ##pad arrays with 0's. Get arrays of size Max\n",
    "    max_col = max([x.shape[1] for x in mfcc])\n",
    "    padded = [np.pad(x, [(0,0), (0, max_col - x.shape[1])], mode = 'constant') for x in mfcc]\n",
    "\n",
    "    ##sanity check\n",
    "    is_shorter = sum([x.shape[1] - max_col for x in padded])\n",
    "    if is_shorter < 0:\n",
    "        print('not padded well')\n",
    "        return -1\n",
    "    else:\n",
    "        return padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## extract MFCC of audio files whose names are in list 'raw_file_list'\n",
    "def process_train_audio(raw_file_list):\n",
    "    \n",
    "    ## remove files that are not .mp3\n",
    "    file_list = [x for x in raw_file_list if '.mp3' in x]\n",
    "    print('Processing ', len(file_list), ' files')\n",
    "\n",
    "    ##sample data to add whitenoise\n",
    "    ##########################\n",
    "    wnratio = 0.7\n",
    "    r = range(int(wnratio*len(file_list)))\n",
    "\n",
    "    sample_file_list = [random.choice(file_list) for i in r]\n",
    "\n",
    "    ##the result is actually not padded just yet\n",
    "    padded_mfcc_result = []\n",
    "    for s in sample_file_list:\n",
    "        y, sr = librosa.load(s)\n",
    "        wn_y = addWhiteNoise(y)\n",
    "        z = librosa.feature.mfcc(y=wn_y, sr=sr, hop_length=hop_length, n_mfcc=13)\n",
    "        padded_mfcc_result.append(z)\n",
    "    \n",
    "\n",
    "    ## Combine two lists of original and noisy lists\n",
    "    ## And pad them\n",
    "    mfcc = [getMFCC(f) for f in file_list]\n",
    "    padded_mfcc = getPaddedMFCC(mfcc + padded_mfcc_result)\n",
    "    \n",
    "    \n",
    "    ### user cannot fix this\n",
    "#     assert (mfcc != -1 and chrom != -1), \"Audio process does not produce uniform format.\"\n",
    "\n",
    "    ## checking the final length\n",
    "    #print(len(mfcc[5]), len(chrom[5]), len(x[5]))\n",
    "    \n",
    "    \n",
    "    ##detect targets from sound names\n",
    "    p = re.compile('^[aeou]|[bcdfghjklmnpqrstwxyz]+(?=[aeiou])|nv|lv')\n",
    "    splt_file = [f.split('/')[-1] for f in file_list+sample_file_list]\n",
    "    target_input = [p.match(f).group() for f in splt_file]\n",
    "    \n",
    "    print('Processing finished')\n",
    "    return padded_mfcc, target_input    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##CHUNK1/2: Compare before and after #\n",
    "######################################\n",
    "######################################\n",
    "######################################\n",
    "import IPython.display as ipd\n",
    "\n",
    "audio_dir = '/Users/panchanok/Desktop/PyHack2019/PyHack2019/sound_samples/xs/'\n",
    "all_files = [audio_dir + d for d in os.listdir(audio_dir)][1:10]\n",
    "shuffle(all_files)\n",
    "\n",
    "print(all_files)\n",
    "file_list = [x for x in all_files if '.mp3' in x]\n",
    "print('Processing ', len(file_list), ' files')\n",
    "\n",
    "##sample data to add whitenoise\n",
    "wnratio = 0.7\n",
    "r = range(int(wnratio*len(file_list)))\n",
    "print(r)\n",
    "sample_file_list = [random.choice(file_list) for i in r]\n",
    "sample_audio = [librosa.load(f) for f in sample_file_list]\n",
    "\n",
    "print('Original File: ')\n",
    "y, sr = librosa.load(sample_file_list[0])\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(y, sr=sr)\n",
    "ipd.Audio(y, rate = 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "##CHUNK2/2: Compare before and after #\n",
    "######################################\n",
    "######################################\n",
    "######################################\n",
    "\n",
    "print('Noisy File: ')\n",
    "new = addWhiteNoise(y)\n",
    "plt.figure(figsize=(14, 5))\n",
    "librosa.display.waveplot(new, sr=sr)\n",
    "ipd.Audio(new, rate = 22050)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing  3240  files\n"
     ]
    }
   ],
   "source": [
    "####This chunk process the audio files\n",
    "\n",
    "### get file name in the directory\n",
    "audio_dir = '/Users/panchanok/Desktop/PyHack2019/sound/eightclasses/'\n",
    "all_files = [audio_dir + d for d in os.listdir(audio_dir)]\n",
    "shuffle(all_files)\n",
    "\n",
    "\n",
    "## Process files to get attributes and targets\n",
    "att, tar = process_train_audio(all_files)\n",
    "\n",
    "## Save the processed files as .pkl files\n",
    "att_file = open(r'eight_mfcc_noise_attr.pkl', 'wb')\n",
    "pickle.dump(att, att_file)\n",
    "att_file.close()\n",
    "\n",
    "tar_file = open(r'eight_mfcc_noise_tar.pkl', 'wb')\n",
    "pickle.dump(tar, tar_file)\n",
    "tar_file.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
